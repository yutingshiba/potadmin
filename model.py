# -*- coding: utf-8 -*-
"""model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cB0E5S3RjG58jQb-zFmrhGwLp3LJkvlN
"""

import numpy as np
import tensorflow as tf
import tensorflow.keras as kr
import tensorflow.keras.layers as ly
import tensorflowjs as tfjs

#global parameters
epochs=3
train_data_size=4096#the number of post
test_data_size=512
sentence_length=64
batch_size=512
embedding_size=64
embedding_maxindex=1000
rnn_size=2
rnn_length=64
dense_size=4
dense_layer=[32,8,4,1]
learning_rate=0.0001

#random data
train_data=np.random.random_integers(embedding_maxindex,size=(train_data_size,sentence_length,embedding_size))
train_label=np.random.random_integers(2,size=(train_data_size))
test_data=np.random.random_integers(embedding_maxindex,size=(test_data_size,sentence_length,embedding_size))
test_label=np.random.random_integers(2,size=(test_data_size))

#model building
model=kr.Sequential()
model.add(ly.Bidirectional(ly.LSTM(rnn_length,return_sequences=True),
                        merge_mode='concat',
                        input_shape=(sentence_length,embedding_size)))
for i in range(0,rnn_size-1):
  model.add(ly.Bidirectional(ly.LSTM(rnn_length,return_sequences=True)))
model.add(ly.Flatten())
for i in range(0,dense_size):
  model.add(ly.Dense(dense_layer[i],
                     activation='relu',
                     bias_regularizer=kr.regularizers.l2(0.01),
                    kernel_initializer='orthogonal'))
model.compile(optimizer=kr.optimizers.Adam(learning_rate),
             loss='binary_crossentropy',
             metrics=['binary_accuracy']
             )
callbacks = [
  tf.keras.callbacks.EarlyStopping(patience=2, monitor='loss'),
  tf.keras.callbacks.TensorBoard(log_dir='./logs')
]
print(model.summary())
model.fit(train_data,train_label,epochs=epochs,batch_size=batch_size,callbacks=callbacks)
model.save('model.h5')
#tfjs.converters.save_keras_model(model, 'model.json')#save tf.js model,if need
print('model saved successfully')
print('test begin')
model.evaluate(train_data,train_label,batch_size=batch_size)



