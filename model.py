# -*- coding: utf-8 -*-
"""model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cB0E5S3RjG58jQb-zFmrhGwLp3LJkvlN
"""
import numpy as np
import tensorflow as tf
import tensorflow.keras as kr
import tensorflow.keras.layers as ly
#import tensorflowjs as tfjs
import data_processor

#global parameters
epochs = 8
#train_data_size=65536#deprecated
#test_data_size=4096#deprecated
sentence_length = 40
batch_size = 512
embedding_size = 300#deprecated

rnn_length = 16
dense_layer = [32, 1]
learning_rate = 0.00005

#true data
#word_vec=data_processor.load_emb_file('wiki.en.vec', True)
word_vec=data_processor.load_emb_file('wiki.en.vec')

#define metric
def tp(y_true,y_pred):
    return kr.backend.sum(y_true * kr.backend.round(y_pred))
def tn(y_true, y_pred):
    return kr.backend.sum((1-y_true) * (1-kr.backend.round(y_pred)))
def fp(y_true, y_pred):
    return kr.backend.sum((1-y_true)*kr.backend.round(y_pred))
def fn(y_true, y_pred):
    return kr.backend.sum(y_true * (1-kr.backend.round(y_pred)))

def precision(y_true,y_pred):
    #return tp(y_true,y_pred)/(tp(y_true,y_pred)+fp(y_true,y_pred))
    tensor1 = tp(y_true,y_pred)
    tensor2 = tp(y_true,y_pred)+fp(y_true,y_pred)
    return ly.Lambda(lambda x: x[0]/x[1])([tensor1, tensor2])
def recall(y_true,y_pred):
    tensor1 = tp(y_true,y_pred)
    tensor2 = tp(y_true,y_pred)+fn(y_true,y_pred)
    return ly.Lambda(lambda x: x[0]/x[1])([tensor1, tensor2])
    # return tp(y_true,y_pred)/(tp(y_true,y_pred)+fn(y_true,y_pred))
def f1(y_true,y_pred):
    #print(kr.backend.int_shape(y_pred))
    #print(kr.backend.eval(y_pred))
    return 2./(1./recall(y_true,y_pred)+1./precision(y_true,y_pred))

#model building
<<<<<<< HEAD
model=kr.Sequential()
model.add(ly.Bidirectional(ly.CuDNNLSTM(rnn_length,return_sequences=True),
                        merge_mode='concat',
                        input_shape=(sentence_length, embedding_size)))
for i in range(0,rnn_size-1):
  model.add(ly.Bidirectional(ly.CuDNNLSTM(rnn_length,return_sequences=False)))
model.add(ly.Flatten())
for i in range(0, len(dense_layer) - 1):
  model.add(ly.Dense(dense_layer[i],
=======
_train = True
if _train:
    model=kr.Sequential()
    model.add(ly.Bidirectional(ly.LSTM(rnn_length,return_sequences=True),
                        merge_mode='concat',
                        input_shape=(sentence_length, embedding_size)))
#model.add(ly.Bidirectional(ly.LSTM(rnn_length,return_sequences=False)))
#model.add(ly.LSTM(rnn_length,return_sequences=False))
    model.add(ly.Flatten())
    for i in range(0, len(dense_layer) - 1):
        model.add(ly.Dense(dense_layer[i],
>>>>>>> a738356c16b56c5396f43a64815571f383cad01a
                    activation='relu',
                    #kernel_regularizer=kr.regularizers.l2(0.01),
                    #bias_regularizer=kr.regularizers.l2(0.01),
                    kernel_initializer='glorot_uniform'))
  
    model.add(ly.Dense(dense_layer[-1],
                   activation='sigmoid',
                   #bias_regularizer=kr.regularizers.l2(0.01),
                   kernel_initializer='glorot_uniform'))
    model.compile(optimizer=kr.optimizers.Adam(learning_rate),
             loss='binary_crossentropy',
             metrics=['binary_accuracy',f1,recall,precision,tp,tn,fp,fn]
#             metrics=['binary_accuracy']
             )
    callbacks = [
    tf.keras.callbacks.EarlyStopping(patience=2, monitor='loss'),
    tf.keras.callbacks.TensorBoard(log_dir='./logs')
    ]
    print(model.summary())

target = 'JP'

train_path='./_data/{}_train.csv'.format(target)
test_path='./_data/{}_test.csv'.format(target)
valid_path='./_data/{}_valid.csv'.format(target)

#train_path='./_data/train_small.csv'.format(target)
#valid_path='./_data/train_small.csv'.format(target)
if _train:
    model.fit_generator(generator=data_processor.generate_from_file(path=train_path, 
                                                                batch_size=batch_size, 
                                                                word_vec=word_vec), 
            steps_per_epoch=(data_processor.get_size(train_path) // batch_size + 1),
            epochs=epochs,
            
            validation_data=data_processor.generate_from_file(path=valid_path,
                                                                batch_size=batch_size,
                                                                word_vec=word_vec),
            validation_steps= ( data_processor.get_size(valid_path) // batch_size +1),
            callbacks=callbacks,
            class_weight = {1: 1.5, 0: 1.})

weight_name = './saved_weight/{}_{}_{}.h5'.format(target, learning_rate, epochs)
model_name = './saved_model/{}_{}_{}.h5'.format(target, learning_rate, epochs)
#model.save(model_name)
if _train:
    '''
    with open(model_name, 'w') as fp:
        fp.write(model.to_json())
    model.save_weights(weight_name)
    '''
    model.save(model_name)
    print('model {} saved successfully'.format(model_name))
else:
    '''
    with open(model_name, 'r') as fp:
        loaded_model_json = fp.read()
    loaded_model = model_from_json(loaded_model_json)
    loaded_model.load_weights(weight_name)
    '''
    loaded_model = kr.models.load_model(model_name) 
    print('model {} loaded successfully'.format(model_name))
    print(loaded_model.summary())

if not _train:
    loaded_model.compile(optimizer=kr.optimizers.Adam(learning_rate),
             loss='binary_crossentropy',
             metrics=['binary_accuracy',f1,recall,precision,tp,tn,fp,fn]
#             metrics=['binary_accuracy']
             )
#tfjs.converters.save_keras_model(model, 'model.json')#save tf.js model,if need
'''
for i in range(0,6):
    print(model.get_weights()[i])
print('test begin')
'''
if _train:
    predict_output = model.predict_generator(generator=data_processor.generate_from_file(path=test_path,
                                                                                    batch_size=batch_size,
                                                                                    word_vec=word_vec),
                                                                                    steps= (data_processor.get_size(test_path) // batch_size + 1))
else:
    predict_output = loaded_model.predict_generator(generator=data_processor.generate_from_file(path=test_path,
                                                                                    batch_size=batch_size,
                                                                                    word_vec=word_vec),
                                                                                    steps= (data_processor.get_size(test_path) // batch_size + 1))

predict_output = np.reshape(predict_output, (predict_output.shape[0],))
#np.set_printoptions(threshold=np.nan)
#define metric
test_true = data_processor.load_test_true(test_path)

print('test_true {}; predict {};'.format(test_true.shape[0], predict_output.shape[0]))
    

def _tp(y_true,y_pred):
    return np.sum(y_true * np.round(y_pred))
def _tn(y_true, y_pred):
    return np.sum((1-y_true) * (1-np.round(y_pred)))
def _fp(y_true, y_pred):
    return np.sum((1-y_true) * np.round(y_pred))
def _fn(y_true, y_pred):
    return np.sum(y_true * (1-np.round(y_pred)))
#test_true = test_true[:100]
#predict_output = predict_output[:100]
#print(test_true)
#print(predict_output)
#print('----')
ttp = _tp(test_true, predict_output)
ttn = _tn(test_true, predict_output)
tfp = _fp(test_true, predict_output)
tfn = _fn(test_true, predict_output)
tpre = ttp / (ttp + tfp)
trec = ttp / (ttp + tfn)
tf1 = 2/(1./trec + 1./tpre)
print('Predict result:')
print('tp: {}'.format(ttp))
print('tn: {}'.format(ttn))
print('fp: {}'.format(tfp))
print('fn: {}'.format(tfn))
print('precision: {}'.format(tpre))
print('recall: {}'.format(trec))
print('f1_score: {}'.format(tf1))
print('Test end')


